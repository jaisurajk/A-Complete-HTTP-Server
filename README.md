The implementation of the HTTP server follows a structured approach, beginning with the core setup. The first step involves parsing command-line arguments, including the port number and optional thread count. The server then creates a listening socket to accept incoming client connections. Additionally, a thread pool and a worker queue are initialized to manage request processing efficiently.

Next, the thread pool is implemented to handle concurrent client requests. At startup, a fixed number of worker threads (default: 4) are created. A dispatcher thread is responsible for accepting connections and assigning them to worker threads via a thread-safe queue. The command to run the multi-threaded HTTP server is ./httpserver [-t threads] <port>, and the server will ensure that worker threads continuously handle requests as they arrive.

Handling HTTP requests is a critical component of the server. The implementation includes support for the GET and PUT methods, allowing clients to retrieve and store file content. To maintain thread safety, I implement mutexes and reader-writer locks (rwlocks), preventing data corruption and ensuring that simultaneous requests do not interfere with each other. For example, let's say there are two requests, R1 and R2. If R2 starts after R1 ends, R2 must appear after R1 in the log.

To maintain a structured and durable record of client requests, I implement an audit log. I have created a function called audit_log where each log entry follows the format "Oper, URI, Status-Code, RequestID" and is written using fprintf(stderr, ...) while I lock and unlock the pthread mutex so only one thread can access a client request at a time. This ensures correct ordering of log entries, so that the order of logged requests must match a consistent serialization of client interactions.

I apply various synchronization mechanisms to ensure correct request ordering. I maintain a linearization order to ensure that requests are processed in a way that upholds consistency. Conflicting operations, such as concurrent GET and PUT requests on the same file, are synchronized to avoid race conditions. I implement mutexes and condition variables (CV) to regulate concurrency while minimizing contention.

Finally, in order to enhance efficiency, I optimize my server in a few different ways. I minimize the thread-contention and implement a non-blocking behavior whenever threads overlap. Memory usage is constrained to a maximum of 10 MB, ensuring lightweight operation. 
